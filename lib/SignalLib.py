#!/usr/bin/env python__version__ = '1.4.3'__verbose__ = 0__use_c_lib__ = Truedebug = Falseimport sysimport numpy as npif __use_c_lib__:    try:        import SignalLibC    except ImportError:        __use_c_lib__ = Falsenoise_profiles = {    'white': {        'noise_calibr': 0.6745,        'resonance_shape': {            -20: 0.000000,            -19: 0.000003,            -18: 0.000006,            -17: 0.000011,            -16: 0.000021,            -15: 0.000040,            -14: 0.000078,            -13: 0.000152,            -12: 0.000302,            -11: 0.000600,            -10: 0.001199,            -9: 0.002394,            -8: 0.004787,            -7: 0.009571,            -6: 0.019140,            -5: 0.038276,            -4: 0.076549,            -3: 0.153095,            -2: 0.306189,            -1: 0.612373,            0: 1.000000,            1: 0.866024,            2: 0.612370,            3: 0.433010,            4: 0.306182,            5: 0.216501,            6: 0.153084,            7: 0.108243,            8: 0.076529,            9: 0.054107,            10: 0.038238,            11: 0.027024,            12: 0.019068,            13: 0.013454,            14: 0.009436,            15: 0.006617,            16: 0.004554,            17: 0.003132,            18: 0.002255,            19: 0.001595,            20: 0.000000,        },        'amplitudes': [[], []],        'fit_params': [[1.0, 0, 0, 0], [2.0, 0, 0, -0.291383]],        'correction_params1': [[2.43013428161, 0.0677523642843], [3.03077600399, 0.051661783511]],        'correction_params2': [[-0.904678564915, 5.08665406929, 0.373858487935],                               [-1.20511815006, 3.49435166944, 0.44501901055]],    },    'pink': {        'noise_calibr': 0.3021,        'resonance_shape': {            -16: 0.000000,            -15: 0.000001,            -14: 0.000002,            -13: 0.000005,            -12: 0.000014,            -11: 0.000039,            -10: 0.000107,            -9: 0.000288,            -8: 0.000773,            -7: 0.002066,            -6: 0.005483,            -5: 0.014412,            -4: 0.037407,            -3: 0.095339,            -2: 0.235994,            -1: 0.549747,            0: 1.000000,            1: 1.099492,            2: 0.943970,            3: 0.762704,            4: 0.598497,            5: 0.461171,            6: 0.350870,            7: 0.264457,            8: 0.197865,            9: 0.147189,            10: 0.108929,            11: 0.080299,            12: 0.058889,            13: 0.043065,            14: 0.031178,            15: 0.022521,            16: 0.015765,            17: 0.010996,            18: 0.007671,            19: 0.005149,            20: 0.000000,        },        'amplitudes': [[], []],        'fit_params': [[2.0, 0.00255496061469, -0.12704208299, -0.135285],                       [4.0, 0.00261811719599, -0.12891652841, -0.379212]],        'correction_params1': [[1.46400717801, 0.128810043947], [1.62852603214, 0.121869938764]],        'correction_params2': [[-2.10, 150, 0.05], [-2.10, 150, 0.05]],    },    'brownian': {        'noise_calibr': 0.0227,        'resonance_shape': {            -15: 0.000000,            -14: 0.000001,            -13: 0.000002,            -12: 0.000007,            -11: 0.000019,            -10: 0.000053,            -9: 0.000149,            -8: 0.000422,            -7: 0.001193,            -6: 0.003364,            -5: 0.009463,            -4: 0.026465,            -3: 0.073121,            -2: 0.196652,            -1: 0.493711,            0: 1.000000,            1: 1.396420,            2: 1.573196,            3: 1.654508,            4: 1.693655,            5: 1.712865,            6: 1.722205,            7: 1.726748,            8: 1.729005,            9: 1.730303,        },        'amplitudes': [[], []],        'fit_params': [[4.0, 0, -0.497071566218, 0.924226], [8.0, 0, -0.496220115605, 0.426950]],        'correction_params1': [[0.0450942027899, 0.552658511862], [0.038978455005, 0.577307034835]],        'correction_params2': [[-2.43887924822, 18.2217376754, 0.0174565477692],                               [-2.10193304634, 100.557509736, 0.118223803724]],    },    'AFM': {        'noise_calibr': 0.4318,        'resonance_shape': {            -20: 0.000000,            -19: 0.000002,            -18: 0.000003,            -17: 0.000006,            -16: 0.000012,            -15: 0.000025,            -14: 0.000050,            -13: 0.000100,            -12: 0.000200,            -11: 0.000404,            -10: 0.000824,            -9: 0.001680,            -8: 0.003532,            -7: 0.007346,            -6: 0.017473,            -5: 0.036993,            -4: 0.074737,            -3: 0.150973,            -2: 0.305025,            -1: 0.611725,            0: 1.000000,            1: 0.887026,            2: 0.626962,            3: 0.447315,            4: 0.320256,            5: 0.223716,            6: 0.161094,            7: 0.115963,            8: 0.082559,            9: 0.058777,            10: 0.043038,            11: 0.031477,            12: 0.022992,            13: 0.014694,            14: 0.010118,            15: 0.006977,            16: 0.005262,            17: 0.004242,            18: 0.003463,            19: 0.003335,            20: 0.000000,        },        'amplitudes': [            [                0.299005,                0.537916,                0.596318,                0.675872,                0.702966,                0.550519,                0.604626,                0.725712,                0.832931,                0.901073,                0.942997,                0.967960,                0.982502,                0.990830,                0.995534,                0.998159,                0.999610,                1.000406,                1.000837,                1.000990,            ],            [                0.334750,                0.913256,                1.239057,                2.042736,                2.928238,                2.823750,                4.602273,                8.419857,                13.898785,                21.130138,                30.943018,                44.515161,                63.489583,                90.167152,                127.784028,                180.903775,                255.970854,                362.092419,                512.143968,                724.312217,            ],        ],        'fit_params': [[1.0, 0, 0, 1.098205], [2.0, 0, 0, 0.807064]],        'correction_params1': [[2.64964024989, 0.0602142387941], [2.76322371019, 0.0607061766533]],        'correction_params2': [[-1.07133291273, 47.1962315149, 0.179088258746],                               [-1.12209568256, 16.6366192054, 0.174235267294]],    },    'tweezers': {        'noise_calibr': 0.4610,        'resonance_shape': {            -20: 0.000000,            -19: 0.000001,            -18: 0.000003,            -17: 0.000005,            -16: 0.000011,            -15: 0.000024,            -14: 0.000051,            -13: 0.000110,            -12: 0.000232,            -11: 0.000487,            -10: 0.001008,            -9: 0.002084,            -8: 0.004280,            -7: 0.008784,            -6: 0.017929,            -5: 0.036583,            -4: 0.074147,            -3: 0.150256,            -2: 0.303076,            -1: 0.610624,            0: 1.000000,            1: 0.881046,            2: 0.631917,            3: 0.452102,            4: 0.323666,            5: 0.231646,            6: 0.165210,            7: 0.117817,            8: 0.084786,            9: 0.060996,            10: 0.043899,            11: 0.031930,            12: 0.023333,            13: 0.016718,            14: 0.012199,            15: 0.008804,            16: 0.006715,            17: 0.004814,            18: 0.003512,            19: 0.002526,            20: 0.000000,        },        'amplitudes': [            [                0.256673,                0.338123,                0.437228,                0.565581,                0.684276,                0.765860,                0.828504,                0.887208,                0.933583,                0.961262,                0.977967,                0.987759,                0.993382,                0.996563,                0.998339,                0.999320,                0.999858,                1.000150,                1.000308,                1.000364,            ],            [                0.355758,                0.534366,                0.921053,                1.692370,                2.892673,                4.525859,                6.855238,                10.326144,                15.287328,                22.121061,                31.643248,                45.005456,                63.828013,                90.394286,                127.927250,                180.980401,                255.990158,                362.056733,                512.048426,                724.156359,            ],        ],        'fit_params': [[1.0, 0, 0, 1.412114], [2.0, 0, 0, 1.120140]],        'correction_params1': [[2.07550280788, 0.0881326298024], [2.74415891092, 0.0623247703709]],        'correction_params2': [[-1.2627935687, 42.1729776326, 0.138500594756],                               [-1.39924019463, 26.924390788, 0.140161716881]],    },}def verbose_mode(status=True):    global __verbose__    __verbose__ = (status == True)def use_c_libraries(state=True, verbose=True):    global __use_c_lib__    __use_c_lib__ = (state and 'SignalLibC' in globals())    if (        __verbose__ or verbose) and state and not __use_c_lib__: print 'warning: module "SignalLibC" not available; using slow Python implementation'def per_ext(y, length):    if len(y) % 2 != 0: y = np.append(y, y[-1])    l = len(y)    for i in range(length): y = np.r_[y[l - 1], y, y[2 * i]]    return ydef symm_ext(y, a):    for i in range(a): y = np.r_[y[1 + 2 * i], y, y[-2 * (i + 1)]]    return ydef convolve(a, b, circshift=0):    N = len(a)    hfl = len(b) / 2    c = np.zeros(N)    for i in range(N):        for j in range(len(b)): c[i] += a[(-hfl + circshift + i + j) % N] * b[-1 - j]    return cdef deconvolve(a, b, circshift=1): return convolve(a, b, circshift)def decompose_per(y, dec_lo, dec_hi):    lf = len(dec_lo)    y = per_ext(y, int(lf / 2))    cA = np.convolve(y, dec_lo)[lf:-lf + 1]    cD = np.convolve(y, dec_hi)[lf:-lf + 1]    return cA, cDdef decompose_per_slow(y, dec_lo, dec_hi):    cA = convolve(y, dec_lo)    cD = convolve(y, dec_hi)    return cA, cDdef decompose_sym(y, dec_lo, dec_hi):    lf = len(dec_lo)    y = symm_ext(y, lf - 1)    cA = np.convolve(y, dec_lo)[lf:-lf + 1]    cD = np.convolve(y, dec_hi)[lf:-lf + 1]    return cA, cDdef recompose_per(cA, cD, rec_lo, rec_hi):    lf = len(rec_lo)    cA = per_ext(cA, int(lf / 2))    yA = np.convolve(cA, rec_lo)[lf - 1:-lf]    lf = len(rec_hi)    cD = per_ext(cD, int(lf / 2))    yD = np.convolve(cD, rec_hi)[lf - 1:-lf]    return yA + yDdef recompose_per_slow(cA, cD, rec_lo, rec_hi):    yA = deconvolve(cA, rec_lo)    yD = deconvolve(cD, rec_hi)    return yA + yDdef recompose_sym(cA, cD, rec_lo, rec_hi):    lf = len(rec_lo)    yA = np.convolve(cA[:-1], rec_lo)[lf - 2:len(cA) - lf + 2]    yD = np.convolve(cD[:-1], rec_hi)[lf - 2:len(cD) - lf + 2]    return yA + yDdef upsampled(y, epsilon=0):    y_up = np.zeros(len(y) * 2)    y_up[epsilon::2] = y    return y_updef dec_filters(wavelet_name):    if wavelet_name == 'haar' or wavelet_name == 'db1':        c = 1 / np.sqrt(2)        return ([c, c], [-c, c])    try:        import pywt        return pywt.Wavelet(wavelet_name).filter_bank[:2]    except ImportError:        raise ValueError('wavelet filter "%s" not implemented' % wavelet_name)def rec_filters(wavelet_name, upsample=0, epsilon_lo=1, epsilon_hi=1):    dec_lo, dec_hi = dec_filters(wavelet_name)    rec_lo, rec_hi = dec_lo[::-1], dec_hi[::-1]    for i in range(upsample):        rec_lo = upsampled(rec_lo, epsilon_lo)        rec_hi = upsampled(rec_hi, epsilon_hi)    return (rec_lo, rec_hi)def DWT(y, wavelet_name, ext_mode='per', epsilon=0):    dec_lo, dec_hi = dec_filters(wavelet_name)    if ext_mode == 'per':        cA, cD = decompose_per(y, dec_lo, dec_hi)    elif ext_mode == 'sym':        cA, cD = decompose_sym(y, dec_lo, dec_hi)    return cA[epsilon::2], cD[epsilon::2]def iDWT(cA, cD, wavelet_name, ext_mode='per', epsilon=0):    rec_lo, rec_hi = rec_filters(wavelet_name)    cA = upsampled(cA, epsilon)    cD = upsampled(cD, epsilon)    if ext_mode == 'per':        return recompose_per(cA, cD, rec_lo, rec_hi)    elif ext_mode == 'sym':        return recompose_sym(cA, cD, rec_lo, rec_hi)def wavedec(y, wavelet_name, ext_mode='sym', levels=0, epsilons=None):    if levels < 1:        dec_lo, dec_hi = dec_filters(wavelet_name)        levels = int(np.ceil(np.log2(len(y) / (len(dec_lo) - 1))))    if epsilons is None: epsilons = [0] * levels    cAs = []    cDs = []    cA = y    for i in xrange(levels):        cA, cD = DWT(cA, wavelet_name, ext_mode, epsilons[i])        cAs.append(cA)        cDs.append(cD)    return cAs, cDsdef waverec(cA, cDs, wavelet_name, ext_mode='sym', levels=0, epsilons=None):    if levels < 1 or levels > len(cDs): levels = len(cDs)    if epsilons is None: epsilons = [0] * levels    for i in xrange(levels): cA = iDWT(cA, cDs[-1 - i], wavelet_name, ext_mode, epsilons[-1 - i])    return cAdef wavedec_from_SWT(SWT_cAs, SWT_cDs):    DWT_cAs = []    DWT_cDs = []    for i in range(len(SWT_cDs)):        d = 1 << (i + 1)        if SWT_cAs is not None: DWT_cAs.append(SWT_cAs[i][::d])        if SWT_cDs is not None: DWT_cDs.append(SWT_cDs[i][::d])    return DWT_cAs, DWT_cDsdef SWT(y, wavelet_name, levels=0):    if __use_c_lib__ and 'SignalLibC' in globals():        if __verbose__: print 'calling fast_SWT()'        return fast_SWT(y, wavelet_name, levels)    if __verbose__: print 'calling slow_SWT()'    return slow_SWT(y, wavelet_name, levels)def fast_SWT(y, wavelet_name, levels=0):    rec_lo, rec_hi = rec_filters(wavelet_name)    max_levels = int(np.ceil(np.log2(len(y))))    if levels < 1 or levels > max_levels: levels = max_levels    cAs, cDs = SignalLibC.SWT(y, rec_lo, levels)    return cAs.reshape(cAs.size / len(y), len(y)), cDs.reshape(cDs.size / len(y), len(y))def slow_SWT(y, wavelet_name, levels=0):    dec_lo, dec_hi = dec_filters(wavelet_name)    max_levels = int(np.ceil(np.log2(len(y))))    if levels < 1 or levels > max_levels: levels = max_levels    cAs = []    cDs = []    cA = y    for i in range(levels):        if i:            dec_lo = upsampled(dec_lo, 0)            dec_hi = upsampled(dec_hi, 0)        cA, cD = decompose_per(cA, dec_lo, dec_hi)        cAs.append(cA)        cDs.append(cD)    return np.array(cAs), np.array(cDs)def iSWT(cA, cDs, wavelet_name, levels=0):    if __use_c_lib__ and 'SignalLibC' in globals():        if __verbose__: print 'calling fast_iSWT()'        return fast_iSWT(cA, cDs, wavelet_name, levels)    if __verbose__: print 'calling slow_iSWT()'    return slow_iSWT(cA, cDs, wavelet_name, levels)def fast_iSWT(cA, cDs, wavelet_name, levels=0):    rec_lo, rec_hi = rec_filters(wavelet_name)    if levels < 1 or levels > len(cDs): levels = len(cDs)    return SignalLibC.iSWT(cA, cDs.flatten(), rec_lo, levels)def slow_iSWT(cA, cDs, wavelet_name, levels=0):    if levels < 1 or levels > len(cDs): levels = len(cDs)    rec_lo, rec_hi = rec_filters(wavelet_name, len(cDs) - 1, 1, 1)  # initially up-sample filters    for i in range(levels):        if i:  # down-sample filters for current level            rec_lo = rec_lo[1::2]            rec_hi = rec_hi[1::2]        cA = recompose_per(cA, cDs[-1 - i], rec_lo, rec_hi) * .5    return cAdef unshift_SWT_coeffs(coeffs):    for i in range(len(coeffs)): coeffs[i] = np.roll(coeffs[i], +(1 << i))def reshift_SWT_coeffs(coeffs):    for i in range(len(coeffs)): coeffs[i] = np.roll(coeffs[i], -(1 << i))def estimate_noise_level(cD, noise_calibr=None): return np.median(    np.abs(cD)) / 0.6745 if noise_calibr is None or noise_calibr == 'white' else np.median(np.abs(cD)) / noise_calibrdef estimate_noise_levels(cDs, noise_calibr=None):    if noise_calibr == 'white': return np.ones(len(cDs)) * estimate_noise_level(cDs[0])    noise_levels = []    for cD in cDs: noise_levels.append(estimate_noise_level(cD, noise_calibr))    return np.array(noise_levels)def estimate_signal_level(cDs, noise_level):    total_level = np.array([np.std(cD) for cD in cDs])    return np.max(np.sqrt(np.maximum(total_level ** 2 - noise_level ** 2, 0)))def ReNoiR_calibrate_on_noise(noise, levels=0, via_PSD=False, N=None):    if via_PSD:        noise = detrend(noise)        noise -= np.mean(noise)        noise /= np.std(noise)        P, f = psd(noise)        if N is None: N = 2 ** levels if levels > 0 else len(noise)        noise = generate_noise_from_PSD(N, P)    cAs, cDs = SWT(noise, 'haar', levels)    amplitudes = {0: [], 1: []}    for i in range(len(cDs)):        amplitudes[0].append(np.std(cDs[i]))        cAs_r1, cDs_r1 = SWT(cDs[i], 'haar', levels)        amplitudes_r1 = []        for j in range(len(cDs_r1)): amplitudes_r1.append(np.std(cDs_r1[j]))        amplitudes[1].append(amplitudes_r1)    return [np.array(amplitudes[0]), np.array(amplitudes[1])]def ReNoiR_NRM_amplitude_correction(N, params):    return N ** (params[1] * np.log2(N) + params[2]) * (2 ** params[3])  # = 2 ** (a * L^2 + b * L + c); with N = 2^Ldef ReNoiR_noise_resonance(dec_path, levels, N, params):    R = len(dec_path)    if R == 0:        amplitudes = np.sqrt(params['fit_params'][0][0] ** np.arange(            levels))  # approximation for high levels (must be scaled by exponential term)        if 'amplitudes' in params:            l = min(len(amplitudes), len(params['amplitudes'][0]))            amplitudes[:l] = params['amplitudes'][0][                             :l]  # precise numerical values (must be scaled by exponential term)        amplitudes *= ReNoiR_NRM_amplitude_correction(N, params['fit_params'][0])  # correction for sample length        return amplitudes    elif R == 1:        level = dec_path[0]        stored_levels = np.array(sorted(params['resonance_shape'].keys()))        resonance = np.empty(levels)        for i in range(levels):            if (i - level) in params['resonance_shape']:                resonance[i] = params['resonance_shape'][i - level]            else:  # find nearest index                indx = np.argmin(np.abs(stored_levels - (i - level)))                key = stored_levels[indx]                resonance[i] = params['resonance_shape'][key]        if 'amplitudes' in params and level < len(params['amplitudes'][1]):            amplitude = params['amplitudes'][1][level]  # precise numerical value (must be scaled by exponential term)        else:            amplitude = np.sqrt(params['fit_params'][1][                                    0] ** level)  # approximation for high levels (must be scaled by exponential term)        amplitude *= ReNoiR_NRM_amplitude_correction(N, params['fit_params'][1])  # correction for sample length        return resonance * amplitude    else:        print 'noise resonance model for R = %d not implemented' % Rdef ReNoiR_thld_corrections(R, N, NSR, params):    if 'correction_params1' in params:        c1 = params['correction_params1'][R]        multiplier = c1[0]        multiplier *= N ** c1[1]  # correct for signal length    else:        multiplier = 1.0    if 'correction_params2' in params:        c2 = params['correction_params2'][R]        multiplier += c2[0] * np.exp(-c2[1] * (NSR - c2[2]) ** 2)  # correct for intermediate SNRs    return multiplierdef get_thresholds(cDs, opt_mode, threshold=None, noise_level=None, signal_level=None, params=None, dec_type='SWT',                   dec_path=[]):    thlds = []    noise_calibr = None if params is None or 'noise_calibr' not in params else params['noise_calibr']    if opt_mode == 'fixed':        thlds = np.ones(len(cDs)) * threshold    elif opt_mode == 'scaled-univ':        if noise_level is None: noise_level = estimate_noise_level(cDs[0], noise_calibr)        thlds = np.ones(len(cDs)) * noise_level * threshold    elif opt_mode == 'scaled-indiv':        if noise_level is None: noise_level = estimate_noise_levels(cDs, noise_calibr)        thlds = noise_level * threshold    elif opt_mode == 'NRM' or opt_mode == 'NRM-plain':  # noise resonance model        if noise_level is None: noise_level = estimate_noise_level(cDs[0], noise_calibr)        if params is None: params = noise_profiles['white']        levels = len(cDs)        N = len(cDs[0])        if opt_mode == 'NRM-plain':            multiplier = 1.0        else:            if signal_level is None: signal_level = estimate_signal_level(cDs, noise_level)            multiplier = ReNoiR_thld_corrections(len(dec_path), N, noise_level / signal_level, params)        return ReNoiR_noise_resonance(dec_path, levels, N, params) * noise_level * multiplier * threshold    elif opt_mode == 'adapted' or opt_mode == 'adapted-plain':        if params is None: sys.exit('error: threshold calibration parameters must be specified')        if noise_level is None: noise_level = estimate_noise_level(cDs[0], noise_calibr)        R = len(dec_path)        levels = len(cDs)        N = len(cDs[0])        if 'amplitudes' in params and params['amplitudes'] is not None:            amplitudes = params['amplitudes']        elif 'noise' in params and params['noise'] is not None:            amplitudes = ReNoiR_calibrate_on_noise(params['noise'] / np.std(params['noise']), levels,                                                   True)  # noise signal should have same length as noisy data; it is scaled to std. dev. 1        elif 'PSD' in params and params['PSD'] is not None:            amplitudes = ReNoiR_calibrate_on_noise(generate_noise_from_PSD(N, params['PSD'], noise_level), levels)        elif 'PSD_file' in params and params['PSD_file'] is not None:            amplitudes = ReNoiR_calibrate_on_noise(generate_noise_from_file(N, params['PSD_file'], noise_level), levels)        else:            sys.exit('error: either wavelet amplitudes, noise signal, PSD, or PSD file must be specified')        if opt_mode == 'adapted-plain':            multiplier = 1.0        else:            if signal_level is None: signal_level = estimate_signal_level(cDs, noise_level)            multiplier = ReNoiR_thld_corrections(R, N, noise_level / signal_level, params)        if R == 0:            return np.array(amplitudes[0]) * noise_level * multiplier * threshold        elif R == 1:            return np.array(amplitudes[1][dec_path[0]]) * noise_level * multiplier * threshold    elif opt_mode == 'SURE':        if dec_type == 'SWT': cAs, cDs = wavedec_from_SWT(None, cDs)        noise_levels = estimate_noise_levels(cDs, noise_calibr)        for i in range(len(cDs)):            cD = cDs[i] / noise_levels[i]            N = len(cD)            cD_sq = np.sort(cD ** 2)            risks = N - 2 * np.arange(1, N + 1) + np.cumsum(cD_sq) + np.arange(N - 1, -1,                                                                               -1) * cD_sq  # vectorized version of: risks[i] = N - 2 * (i + 1) + np.sum(cD_sq[:i]) + (N - i) * cD_sq[i]            if np.max(cD) <= 0 or noise_levels[i] <= 0:                thlds.append(0)            else:                thlds.append(np.sqrt(cD_sq[np.argmin(risks)]))        thlds = np.array(thlds) * noise_levels    elif opt_mode == 'bayes':  # use soft-thresholding        if dec_type == 'SWT': cAs, cDs = wavedec_from_SWT(None, cDs)        var_noise = estimate_noise_levels(cDs, noise_calibr) ** 2        var_cDs = np.array([np.std(cD) for cD in cDs]) ** 2        sigma_source = np.sqrt(np.maximum(var_cDs - var_noise, 0))        oldsettings = np.seterr(divide='ignore')        thlds = var_noise / sigma_source        np.seterr(**oldsettings)    elif opt_mode == 'minimax':        if dec_type == 'SWT': cAs, cDs = wavedec_from_SWT(None, cDs)        noise_levels = estimate_noise_levels(cDs, noise_calibr)        N = sum([len(cD) for cD in cDs]) + 1        if N <= 32:            thlds = np.zeros(len(cDs))        else:            thlds = noise_levels * (0.3936 + 0.1829 * np.log2(N))    elif opt_mode == 'universal' or opt_mode == 'visu':  # use hard-thresholding        if dec_type == 'SWT': cAs, cDs = wavedec_from_SWT(None, cDs)        noise_levels = estimate_noise_levels(cDs, noise_calibr)        N = sum([len(cD) for cD in cDs]) + 1        thlds = noise_levels * np.sqrt(2 * np.log(N))    elif opt_mode == 'universal-soft' or opt_mode == 'visu-soft':  # use soft-thresholding, see http://www.bearcave.com/misl/misl_tech/wavelets/histo/index.html        if dec_type == 'SWT': cAs, cDs = wavedec_from_SWT(None, cDs)        noise_levels = estimate_noise_levels(cDs, noise_calibr)        N = sum([len(cD) for cD in cDs]) + 1        thlds = noise_levels * np.sqrt(2 * np.log(N)) / np.sqrt(N)    elif opt_mode == 'fixed_calibration':  # bad idea        N = len(cDs[0])        if params is None or 'fit_params' not in params:            fit_params = [3.51 / (4096 ** 0.26), 2.70, 0, 1.43]        else:            fit_params = params['fit_params']        if noise_level is None: noise_level = estimate_noise_level(cDs[0], noise_calibr)        if signal_level is None: signal_level = estimate_signal_level(cDs, noise_level)        # thlds = np.ones(len(cDs)) * noise_level * 51 * (1 - np.exp(-0.33 * (noise_level / signal_level)))        # thlds = np.ones(len(cDs)) * noise_level * max(2 * np.pi, 51 * (1 - np.exp(-0.33 * (noise_level / signal_level))))        # thlds = np.ones(len(cDs)) * noise_level * max(2 * np.pi, 3.7 * np.exp(2.7 / (1 + (noise_level / signal_level) ** -1.3)))        # thlds = np.ones(len(cDs)) * noise_level * 6.28 * np.exp(1.06 / (0.5 + (signal_level / noise_level) ** 1.79))        # thlds = np.ones(len(cDs)) * noise_level * 4.0 * np.exp(2.08 / (0.81 + (signal_level / noise_level) ** 1.57))        # thlds = np.ones(len(cDs)) * noise_level * 4.0 * np.exp(0.76 / (0.30 + 0.66 * (signal_level / noise_level) ** 2.20))        # thlds = np.ones(len(cDs)) * noise_level * fit_params[0] * np.exp(fit_params[1] / (fit_params[2] + fit_params[3] * (signal_level / noise_level) ** fit_params[4]))        thlds = np.ones(len(cDs)) * noise_level * (N ** 0.26) * fit_params[0] * np.exp(            fit_params[1] / (1 + (noise_level / signal_level + fit_params[2]) ** -fit_params[3])) * threshold    else:        print 'threshold mode "%s" not implemented' % opt_mode    return thldsdef threshold_single(y, threshold, thld_mode='hard'):    if threshold == 0:      return    if threshold == np.inf:        y = np.zeros_like(y)    else:        if thld_mode == 'hard':            y[np.abs(y) <= threshold] = 0        elif thld_mode == 'soft':            y[np.abs(y) <= threshold] = 0            y[y > +threshold] -= threshold            y[y < -threshold] += thresholddef threshold_all(y, threshold, thld_mode='hard'):    if type(threshold) == list or type(threshold) == np.ndarray:        for i in range(min(len(y), len(threshold))): threshold_single(y[i], threshold[i], thld_mode)    else:        if threshold == 0:      return        if threshold == np.inf:            y = np.zeros_like(y)        else:            for i in range(len(y)): threshold_single(y[i], threshold, thld_mode)def merge_coeffs(y1, y2, threshold):    if type(threshold) == list or type(threshold) == np.ndarray:        for i in range(min(len(y1), len(threshold))):            if threshold[i] == 0:      continue            if threshold[i] == np.inf:                y1[i] = y2[i]            else:                keys = abs(y1[i]) < threshold[i]                y1[i][keys] = y2[i][keys]    else:        if threshold == 0:      return        if threshold == np.inf:            y1 = y2        else:            for i in range(len(y1)):                keys = abs(y1[i]) < threshold                y1[i][keys] = y2[i][keys]def extend_signal_left(y, N, mode=0):    e = N - len(y)    if e > 0:        if mode == 0: return np.append(y[-e:], y)  # periodic extension        if mode == 1: return np.append(y[:e][::-1], y)  # mirror-symmetric extension        if mode == 2: return np.append(2 * y[0] - y[1:e + 1][::-1], y)  # point-symmetric extension        if mode == 3: return np.append(np.zeros(e), y)  # extend with zeros        if mode == 4: return np.append(np.ones(e) * y[0], y)  # extend with first value    return ydef extend_signal_right(y, N, mode=0):    e = N - len(y)    if e > 0:        if mode == 0: return np.append(y, y[:e])  # periodic extension        if mode == 1: return np.append(y, y[-e:][::-1])  # mirror-symmetric extension        if mode == 2: return np.append(y, 2 * y[-1] - y[-e - 1:-1][::-1])  # point-symmetric extension        if mode == 3: return np.append(y, np.zeros(e))  # extend with zeros        if mode == 4: return np.append(y, np.ones(e) * y[-1])  # extend with last value    return ydef extend_signal(y, N, mode=0): return extend_signal(y, N, mode)def extend_signal_both(y, N, mode=0):    e = N - len(y)    if e > 0:        if mode == 0: return np.concatenate((y[-e:], y, y[:e]))  # periodic extension        if mode == 1: return np.concatenate((y[:e][::-1], y, y[-e:][::-1]))  # mirror-symmetric extension        if mode == 2: return np.concatenate(            (2 * y[0] - y[1:e + 1][::-1], y, 2 * y[-1] - y[-e - 1:-1][::-1]))  # point-symmetric extension        if mode == 3: return np.concatenate((np.zeros(e), y, np.zeros(e)))  # extend with zeros        if mode == 4: return np.concatenate((np.ones(e) * y[0], y, np.ones(e) * y[-1]))  # extend with first/last value    return ydef denoise_DWT(y, opt_mode='SURE', wavelet_name='haar', levels=0, thld_mode='soft', threshold=0, noise_level=None,                signal_level=None, thld_calibr_params=None):    len_y = len(y)    max_levels = int(np.ceil(np.log2(len_y)))    if levels < 1 or levels > max_levels: levels = max_levels    y = extend_signal(y, 1 << levels, 0)    cAs, cDs = wavedec(y, wavelet_name, levels=levels)    if noise_level is None: noise_level = estimate_noise_level(cDs[0],                                                               None if thld_calibr_params is None or 'noise_calibr' not in thld_calibr_params else                                                               thld_calibr_params['noise_calibr'])    if signal_level is None: signal_level = estimate_signal_level(cDs, noise_level)    threshold_all(cDs, get_thresholds(cDs, opt_mode=opt_mode, threshold=threshold, noise_level=noise_level,                                      signal_level=signal_level, params=thld_calibr_params, dec_type='DWT'), thld_mode)    return waverec(cAs[-1], cDs, wavelet_name, levels=levels)def denoise_SWT_man(y, threshold, wavelet_name='haar', levels=0, thld_mode='hard', thld_type=0): return ReNoiR_man(y=y,                                                                                                                   T0=np.inf,                                                                                                                   T1=threshold,                                                                                                                   R=0,                                                                                                                   wavelet_name=wavelet_name,                                                                                                                   levels=levels,                                                                                                                   thld_mode=thld_mode,                                                                                                                   thld_type=thld_type)  # like ReNoiR, but no recursion and no mergingdef denoise_SWT(y, opt_mode='SURE', threshold=1.0, wavelet_name='haar', levels=0, thld_mode='soft', noise_level=None,                signal_level=None, thld_calibr_params=None): return ReNoiR(y=y, opt_mode=opt_mode, threshold=threshold,                                                                           R=0, wavelet_name=wavelet_name,                                                                           levels=levels, thld_mode=thld_mode,                                                                           noise_level=noise_level,                                                                           signal_level=signal_level,                                                                           thld_calibr_params=thld_calibr_params)  # like ReNoiR, but no recursion and no mergingdef denoise_RSWT_man(y, threshold, R=1, wavelet_name='haar', levels=0, thld_mode='hard', thld_type=0):    if R == 0: return denoise_SWT_man(y, threshold=threshold, wavelet_name=wavelet_name, levels=levels,                                      thld_mode=thld_mode, thld_type=thld_type)    return ReNoiR_man(y=y, T0=np.inf, T1=threshold, R=R, wavelet_name=wavelet_name, levels=levels, thld_mode=thld_mode,                      thld_type=thld_type)  # like ReNoiR, but no mergingdef denoise_RSWT(y, opt_mode='SURE', threshold=1.0, R=1, wavelet_name='haar', levels=0, thld_mode='soft',                 noise_level=None, signal_level=None, thld_calibr_params=None):    if R == 0: return denoise_SWT(y, opt_mode=opt_mode, threshold=threshold, wavelet_name=wavelet_name, levels=levels,                                  thld_mode=thld_mode, noise_level=noise_level, signal_level=signal_level,                                  thld_calibr_params=thld_calibr_params)    if type(opt_mode) == list:        opt_mode = ['scaled-univ'] + opt_mode    else:        opt_mode = ['scaled-univ'] + [opt_mode] * R    if type(threshold) == list:        threshold = [np.inf] + threshold    else:        threshold = [np.inf] + [threshold] * R    return ReNoiR(y=y, opt_mode=opt_mode, threshold=threshold, R=R, wavelet_name=wavelet_name, levels=levels,                  thld_mode=thld_mode, noise_level=noise_level, signal_level=signal_level,                  thld_calibr_params=thld_calibr_params)  # like ReNoiR, but no mergingdef ReNoiR_man(y, T0, T1=np.inf, R=1, wavelet_name='haar', levels=0, thld_mode='hard', thld_type=0):    if __use_c_lib__ and 'SignalLibC' in globals():        if __verbose__: print 'calling fast_ReNoiR_man()'        return fast_ReNoiR_man(y, T0, T1, R, wavelet_name, levels, thld_mode, thld_type)    if __verbose__: print 'calling slow_ReNoiR_man()'    return slow_ReNoiR_man(y, T0, T1, R, wavelet_name, levels, thld_mode, thld_type)def fast_ReNoiR_man(y, T0, T1=np.inf, R=1, wavelet_name='haar', levels=0, thld_mode='hard', thld_type=0):    rec_lo, rec_hi = rec_filters(wavelet_name)    len_y = len(y)    max_levels = int(np.ceil(np.log2(len_y)))    if levels < 1 or levels > max_levels: levels = max_levels    y = extend_signal(y, 1 << levels, 0)    return SignalLibC.ReNoiR_man(y, T0, T1, R, rec_lo, levels, 1 if thld_mode == 'soft' else 0, thld_type)[:len_y]def slow_ReNoiR_man(y, T0, T1=np.inf, R=1, wavelet_name='haar', levels=0, thld_mode='hard', thld_type=0,                    return_thld=False):    if not (T0 > 0 and T1 > 0): return y    len_y = len(y)    max_levels = int(np.ceil(np.log2(len_y)))    if levels < 1 or levels > max_levels: levels = max_levels    y = extend_signal(y, 1 << levels, 0)    cAs, cDs = SWT(y, wavelet_name, levels)    if R > 0:        cDs_denoised = np.empty_like(cDs)        for i in range(len(cDs)):            if thld_type == 1 and R == 1:                cDs_denoised[i], thld2 = slow_ReNoiR_man(cDs[i], T0, thld2 if i else T1, R - 1, wavelet_name, levels,                                                         thld_mode, 1 if i else 2,                                                         True)  # next recursion level (thld_type 1 can slightly improve results at intermediate noise levels, but is not effective for R=0)            else:                cDs_denoised[i] = slow_ReNoiR_man(cDs[i], T0, T1, R - 1, wavelet_name, levels, thld_mode,                                                  thld_type)  # next recursion level        if thld_type == 3:            thld = T0        else:            thld = T0 * np.std(cDs[0])        merge_coeffs(cDs, cDs_denoised, thld)  # merge cDs and cDs_denoised using T0    else:        if thld_type == 0:            thld = T1 * np.std(cDs[0])        elif thld_type == 1:            thld = T1        elif thld_type == 2:            thld = T1 * np.std(cDs)        elif thld_type == 3:            thld = T1        else:            thld = T1        threshold_all(cDs, thld, thld_mode)  # last recursion level -> conventional thresholding based on T1    if return_thld: return (iSWT(cAs[-1], cDs, wavelet_name, levels)[:len_y], thld)    return iSWT(cAs[-1], cDs, wavelet_name, levels)[:len_y]def ReNoiR(y, opt_mode='NRM', threshold=1.0, R=1, wavelet_name='haar', levels=0, thld_mode='hard', noise_level=None,           signal_level=None, thld_calibr_params=None, dec_path=[]):    if type(opt_mode) != list: opt_mode = [opt_mode] * (R + 1)    if type(threshold) != list: threshold = [threshold] * (R + 1)    len_y = len(y)    max_levels = int(np.ceil(np.log2(len_y)))    if levels < 1 or levels > max_levels: levels = max_levels    y = extend_signal(y, 1 << levels, 0)    cAs, cDs = SWT(y, wavelet_name, levels)    if noise_level is None: noise_level = estimate_noise_level(cDs[0],                                                               None if thld_calibr_params is None or 'noise_calibr' not in thld_calibr_params else                                                               thld_calibr_params['noise_calibr'])    if signal_level is None: signal_level = estimate_signal_level(cDs, noise_level)    if R > 0:        cDs_denoised = np.empty_like(cDs)        for i in range(len(cDs)): cDs_denoised[i] = ReNoiR(cDs[i], opt_mode[1:], threshold[1:], R - 1, wavelet_name,                                                           levels, thld_mode, noise_level, signal_level,                                                           thld_calibr_params, dec_path + [i])  # next recursion level        merge_coeffs(cDs, cDs_denoised,                     get_thresholds(cDs, opt_mode=opt_mode[0], threshold=threshold[0], noise_level=noise_level,                                    signal_level=signal_level, params=thld_calibr_params, dec_type='SWT',                                    dec_path=dec_path))  # merge cDs and cDs_denoised    else:        threshold_all(cDs, get_thresholds(cDs, opt_mode=opt_mode[0], threshold=threshold[0], noise_level=noise_level,                                          signal_level=signal_level, params=thld_calibr_params, dec_type='SWT',                                          dec_path=dec_path),                      thld_mode)  # last recursion level -> conventional thresholding    return iSWT(cAs[-1], cDs, wavelet_name, levels)[:len_y]def WPdec(ci, levels, dec_lo, dec_hi):    if levels < 1: return ci    co = []    for i in range(len(ci)): co.extend(decompose_per(ci[i], dec_lo, dec_hi))    if levels > 1: return WPdec(co, levels - 1, upsampled(dec_lo), upsampled(dec_hi))    return np.array(co)def WPrec(ci, levels, rec_lo, rec_hi):    if levels < 1 or len(ci) < 2: return ci    co = []    level = np.ceil(np.log2(len(ci))) - 1    for i in range(0, len(ci), 2):        y = recompose_per(ci[i], ci[i + 1], rec_lo, rec_hi) * .5        y = np.roll(y, (1 << level) - 1)  # perform circular shift        co.append(y)    if levels > 1: return WPrec(co, levels - 1, rec_lo[::2], rec_hi[::2])    return co[0]def WPdenoise(y, T, levels=0, wavelet_name='haar', thld_mode='hard'):    if not T > 0: return y    max_levels = int(np.ceil(np.log2(len(y))))    if levels < 1 or levels > max_levels: levels = max_levels    C = WPdec([y], levels, *dec_filters(wavelet_name))    threshold_all(C, T * np.std(C[1]), thld_mode)    # max_levels = np.ceil(np.log2(len(ci)))    # if levels > max_levels: levels = max_levels    y = WPrec(C, levels, *rec_filters(wavelet_name, levels - 1))    return y# def gauss_filter(y, sigma=None, size=None):#  from scipy.ndimage import gaussian_filter1d#  return gaussian_filter1d(y, sigma)def gauss_filter(y, sigma=None, size=None, mode='reflect'):    if sigma == 0 or (sigma is None and size is None): return y    if size is None: size = int(5 * sigma)    sigma = size / 10. if sigma is None else float(sigma)    if size > y.size: return np.zeros_like(y)    try:        import scipy.ndimage        return scipy.ndimage.gaussian_filter1d(y, sigma, mode=mode)    except ImportError:        s = np.empty(size * 2 + 1)        s[size:] = np.exp(-0.5 * (np.arange(size + 1) / sigma) ** 2)        s[:size] = s[size + 1:][::-1]        s /= np.sum(s)        return np.convolve(y, s, 'same')  # produces boundary effectsdef find_local_maxima(y, num_steps=None, threshold=None, min_height=0, margin_lt=0, margin_rt=0, thld_mode=0):    if num_steps is not None and num_steps <= 0: return np.array([])    if threshold is None:        min_value = None  # no threshold    elif thld_mode == 1:        min_value = threshold * np.std(y)  # threshold relative to the standard deviation    elif thld_mode == 2:  # threshold relative to the standard deviation of the upper half plane        err_status = np.seterr(all='ignore')        half_plane = y[y >= 0]        np.seterr(**err_status)        if not len(half_plane): return np.array([])        min_value = threshold * np.std(half_plane)    elif thld_mode == 3:        min_value = threshold * np.median(y)  # threshold relative to the median    elif thld_mode == 4:  # threshold relative to the median of the upper half plane        err_status = np.seterr(all='ignore')        half_plane = y[y >= 0]        np.seterr(**err_status)        if not len(half_plane): return np.array([])        min_value = threshold * np.median(half_plane)    else:        min_value = threshold  # absolute threshold    if __use_c_lib__ and 'SignalLibC' in globals():        if __verbose__: print 'calling SignalLibC.find_local_maxima()'        maxima = SignalLibC.find_local_maxima(y, float('nan') if min_value is None else min_value, min_height,                                              margin_lt, margin_rt)    else:        if __verbose__: print 'using pure Python implementation of find_local_maxima()'        maxima = []        for i in range(1 + margin_lt, y.size - 1 - margin_rt):            if y[i - 1] < y[i] and y[i + 1] < y[i] and (min_value is None or y[i] >= min_value):                if min_height == 0:                    maxima.append(i)                else:                    lt = rt = i                    while lt > 0 and y[lt - 1] < y[lt]: lt -= 1                    while rt < y.size - 1 and y[rt + 1] < y[rt]: rt += 1                    if min(y[i] - y[lt], y[i] - y[rt]) >= min_height: maxima.append(i)        maxima = np.array(maxima)    if maxima.size > 0 and num_steps > 0: maxima = np.sort(maxima[np.argsort(y[maxima])][-num_steps:])    return maximadef refine_local_maxima(y, maxima):    maxima = list(maxima)  # make copy    for max_no, i in enumerate(maxima):        j = i        while i > 0 and y[i - 1] > y[i]: i -= 1        while j < y.size - 1 and y[j + 1] > y[j]: j += 1        maxima[max_no] = i if y[i] >= y[j] else j    return maximadef calc_curvature(y, remove_thld_edges=False):    crvtr = np.empty_like(y)    crvtr[0] = 0    crvtr[len(y) - 1] = 0    crvtr[1:-1] = y[:-2] + y[2:] - 2 * y[1:-1]    crvtr[(crvtr < 0) & (y < 0)] = 0  # consider only convex  environments in the lower y plane    crvtr[(crvtr > 0) & (y > 0)] = 0  # consider only concave environments in the upper y plane    if remove_thld_edges:  # eliminate thresholding effect        mask = (y == 0)        crvtr[mask] = 0        crvtr[:-1][mask[1:]] = 0        crvtr[1:][mask[:-1]] = 0    return crvtrdef detect_steps_by_SWT(y, direction=0, threshold=0, number_of_steps=None, sigma=0.5, noise_threshold=2.5, level=None,                        remove_thld_edges=False):    len_y = len(y)    y = extend_signal(y, 1 << int(np.ceil(np.log2(len_y))), 0)    cAs, cDs = SWT(y, 'haar', 0 if not level >= 0 else level + 1)    unshift_SWT_coeffs(cDs)    y = y[:len_y]    cDs = cDs[:, :len_y]    noise_thld = noise_threshold * np.std(cDs[0])    curvature = np.zeros(len_y)    for level in range(len(cDs)):        cDs[level][abs(cDs[level]) < noise_thld] = 0  # remove noise below threshold        curvature += calc_curvature(cDs[level], remove_thld_edges)  # sum up the curvatures from each level    curvature = gauss_filter(curvature, sigma)  # smooth sum of curvatures    if not direction < 0:        up = find_local_maxima(+curvature, num_steps=number_of_steps, threshold=threshold, thld_mode=2)        if direction > 0: return up    if not direction > 0:        dn = find_local_maxima(-curvature, num_steps=number_of_steps, threshold=threshold, thld_mode=2)        if direction < 0: return dn    return up, dndef RMS(y, free_params=0):    if free_params > 0: return np.sqrt(np.sum(y ** 2) / (len(y) - free_params))    return np.sqrt(np.mean(y) ** 2 + np.std(y) ** 2)def lin_fit(x, y, slope=None, interception=None, return_y=False):    N = len(y)    if N == 1: return (0, y[0], y) if return_y else (0, y[0])    if N == 0: return (np.nan, np.nan, y) if return_y else (np.nan, np.nan)    sum_x = np.sum(x) if x is not None else N * (N - 1) / 2    sum_y = np.sum(y)    if slope is None:        if interception is None:            sum_x_sq = np.dot(x, x) if x is not None else sum_x * (2 * N - 1) / 3            if x is None: x = np.arange(N)            slope = float(N * np.dot(x, y) - sum_x * sum_y) / (N * sum_x_sq - sum_x * sum_x)        else:            slope = float(sum_y - interception * N) / sum_x    if interception is None: interception = float(sum_y - slope * sum_x) / N    if return_y:        if x is None: x = np.arange(N)        return slope, interception, slope * x + interception    return slope, interceptiondef lin_fit_opt(x, y, min_fit_len=None):    if __use_c_lib__ and 'SignalLibC' in globals():        if __verbose__: print 'calling SignalLibC.lin_fit_opt()'        return SignalLibC.lin_fit_opt(x, y, min_fit_len if min_fit_len > 0 else 0)    if __verbose__: print 'using pure Python implementation of lin_fit_opt()'    N = len(x)    if min_fit_len is None or min_fit_len == 0: min_fit_len = N    if min_fit_len <= 0 or min_fit_len > N: return np.nan, np.nan, 0, np.nan    if min_fit_len == 1: return 0, y[0], N, np.nan    if min_fit_len == 2:        slope = (y[1] - y[0]) / (x[1] - x[0])        return slope, y[0] - slope * x[0], N, np.nan    RMSs = []    results = []    for i in range(min_fit_len, N + 1):        sum_x = np.sum(x[:i])        sum_y = np.sum(y[:i])        sum_x_sq = np.sum(x[:i] ** 2)        slope = float(i * np.dot(x[:i], y[:i]) - sum_x * sum_y) / (i * sum_x_sq - sum_x ** 2)        interception = float(sum_y - slope * sum_x) / i        RMSs.append(RMS(y[:i] - slope * x[:i] - interception, 2))        results.append((slope, interception, i))    opt_index = np.argmin(RMSs)    slope, interception, fit_len = results[opt_index]    return slope, interception, fit_len, RMSs[opt_index]def split_lin_fit(y, slope=None, return_y=False):  # for equidistant data only    N = len(y)    N_hf = N / 2    x = np.arange(N)    sum_x_lt = N_hf * (N_hf - 1) / 2    sum_x_rt = N * (3 * N - 2) / 8    sum_y_lt = np.sum(y[:N_hf])    sum_y_rt = np.sum(y[N_hf:])    if slope is None:        sum_x_sq = N * (N - 1) * (2 * N - 1) / 6        slope = float(N_hf * np.dot(x, y) - sum_x_lt * sum_y_lt - sum_x_rt * sum_y_rt) / (        N_hf * sum_x_sq - sum_x_lt ** 2 - sum_x_rt ** 2)    interception_lt = float(sum_y_lt - slope * sum_x_lt) / N_hf    interception_rt = float(sum_y_rt - slope * sum_x_rt) / N_hf    if return_y: return slope, interception_lt, interception_rt, np.r_[        slope * x[:N_hf] + interception_lt, slope * x[N_hf:] + interception_rt]    return slope, interception_lt, interception_rtdef calc_moving_step_fit(y, sigma=0, window=10, flank_width=0, fit_order=0, mode=None, output_mode=None, slope=None,                         slope_lt=None, slope_rt=None, delta_x=None, padding=0):    if output_mode is None: output_mode = 7 if mode is None else 0    if mode >= 0 and mode <= 4: output_mode |= [4, 3, 5, 6, 7][mode]    if padding > 0: y = np.r_[[np.mean(y[:padding])] * window, y, [np.mean(y[-padding:])] * window]    y = gauss_filter(y, sigma)    if __use_c_lib__ and 'SignalLibC' in globals():        if __verbose__: print 'calling SignalLibC.calc_moving_step_fit()'        RSS_p, RSS_n, heights = SignalLibC.calc_moving_step_fit(y, window, flank_width, fit_order, output_mode, slope,                                                                slope_lt, slope_rt, delta_x)    else:        if __verbose__: print 'using pure Python implementation of calc_moving_step_fit()'        RSS_p = RSS_n = heights = None        if window > 1:            if output_mode & 1: RSS_p = np.zeros(y.size)            if output_mode & 2: RSS_n = np.zeros(y.size)            if output_mode & 4: heights = np.zeros(y.size)            if fit_order == 0:                for i in range(flank_width + window, y.size - flank_width - window + 1):                    mean_lt = np.mean(y[i - flank_width - window:i - flank_width])                    mean_rt = np.mean(y[i + flank_width:i + flank_width + window])                    if output_mode & 2: mean = np.mean(y[i - flank_width - window:i + flank_width + window])                    if output_mode & 1: RSS_p[i - 1] = np.sum(                        (y[i - flank_width - window:i - flank_width] - mean_lt) ** 2) + np.sum(                        (y[i + flank_width:i + flank_width + window] - mean_rt) ** 2)                    if output_mode & 2: RSS_n[i - 1] = np.sum(                        (y[i - flank_width - window:i + flank_width + window] - mean) ** 2)                    if output_mode & 4: heights[i - 1] = mean_rt - mean_lt            elif fit_order == 1:                if slope_lt is None and slope_rt is None:  # 1 split fit with 2 optimized identical slopes                    if slope is not None and delta_x is not None: slope *= delta_x                    for i in range(flank_width + window, y.size - flank_width - window + 1):                        m_split, t_lt, t_rt, fit_split = split_lin_fit(                            y[i - flank_width - window:i + flank_width + window], slope=slope, return_y=True)                        if output_mode & 2: m, t, fit = lin_fit(None,                                                                y[i - flank_width - window:i + flank_width + window],                                                                slope=slope, return_y=True)                        if output_mode & 1: RSS_p[i - 1] = np.sum(                            (y[i - flank_width - window:i + flank_width + window] - fit_split) ** 2)                        if output_mode & 2: RSS_n[i - 1] = np.sum(                            (y[i - flank_width - window:i + flank_width + window] - fit) ** 2)                        if output_mode & 4: heights[i - 1] = t_rt - t_lt                else:  # 2 separate fits with 2 fixed slopes                    if slope is not None and delta_x is not None: slope *= delta_x                    if slope_lt is not None and delta_x is not None: slope_lt *= delta_x                    if slope_rt is not None and delta_x is not None: slope_rt *= delta_x                    for i in range(flank_width + window, y.size - flank_width - window + 1):                        m_lt, t_lt, fit_lt = lin_fit(None, y[i - flank_width - window:i - flank_width], slope=slope_lt,                                                     return_y=True)                        m_rt, t_rt, fit_rt = lin_fit(None, y[i + flank_width:i + flank_width + window], slope=slope_rt,                                                     return_y=True)                        if output_mode & 2: m, t, fit = lin_fit(None,                                                                y[i - flank_width - window:i + flank_width + window],                                                                slope=slope, return_y=True)                        if output_mode & 1: RSS_p[i - 1] = np.sum(                            (y[i - flank_width - window:i - flank_width] - fit_lt) ** 2) + np.sum(                            (y[i + flank_width:i + flank_width + window] - fit_rt) ** 2)                        if output_mode & 2: RSS_n[i - 1] = np.sum(                            (y[i - flank_width - window:i + flank_width + window] - fit) ** 2)                        if output_mode & 4: heights[i - 1] = (m_rt - m_lt) * (i - 1) + t_rt - t_lt - m_rt * (                        i + flank_width) + m_lt * (                        i - flank_width - window)  # last 2 terms compensate for the shift of the x coordinates        elif flank_width > 0:  # window <= 1            if output_mode & 1: RSS_p = np.zeros(y.size)            if output_mode & 2:                RSS_n = np.zeros(y.size)                for i in range(flank_width + 1, y.size - flank_width): RSS_n[i - 1] = np.sum((y[                                                                                              i - flank_width - 1:i + flank_width + 1] - np.mean(                    y[i - flank_width - 1:i + flank_width + 1])) ** 2)            if output_mode & 4:                heights = np.zeros(y.size)                for i in range(flank_width + 1, y.size - flank_width): heights[i - 1] = y[i + flank_width] - y[                    i - flank_width - 1]        else:  # window <= 1 and flank_width <= 0            if output_mode & 1: RSS_p = np.zeros(y.size)            if output_mode & 2:                RSS_n = np.zeros(y.size)                for i in range(1, y.size): RSS_n[i - 1] = np.sum((y[i - 1:i + 1] - np.mean(y[i - 1:i + 1])) ** 2)            if output_mode & 4: heights = np.diff(np.append(y, y[-1]))    if padding > 0:        if RSS_p is not None: RSS_p = RSS_p[window:-window]        if RSS_n is not None: RSS_n = RSS_n[window:-window]        if heights is not None: heights = heights[window:-window]    return (RSS_p, RSS_n, heights)def calc_MSF_indicator(result, mode=0):    err_status = np.seterr(all='ignore')    if mode == 0:        indicator = result[2]  # heights    # elif mode == 1: indicator = result[1] / result[0]                      # RSS_n / RSS_p    elif mode == 1:        indicator = result[1] - result[0]  # RSS_n - RSS_p    elif mode == 2:        indicator = result[2] / result[0]  # heights / RSS_p    # elif mode == 2: indicator = result[2] / np.sqrt(result[0])             # heights / sqrt(RSS_p)    elif mode == 3:        indicator = result[2] * result[1]  # heights * RSS_n    # elif mode == 4: indicator = result[2] * result[1] / result[0]          # heights * RSS_n / RSS_p    # elif mode == 4: indicator = result[2] * np.sqrt(result[1] / result[0]) # heights * sqrt(RSS_n / RSS_p)    elif mode == 4:        indicator = result[2] * (result[1] - result[0])  # heights * (RSS_n - RSS_p)    else:        print 'MSF mode %d not implemented' % mode        indicator = None    np.seterr(**err_status)    return indicatordef detect_steps_by_MSF(y, direction=0, threshold=None, number_of_steps=None, margin_lt=None, margin_rt=None, sigma=0,                        window=10, flank_width=0, fit_order=0, mode=4, slope=None, slope_lt=None, slope_rt=None,                        delta_x=None, padding=0, thld_mode=2, return_indicator=False):    result = calc_moving_step_fit(y, sigma=sigma, window=window, flank_width=flank_width, fit_order=fit_order,                                  mode=mode, slope=slope, slope_lt=slope_lt, slope_rt=slope_rt, delta_x=delta_x,                                  padding=padding)    indicator = calc_MSF_indicator(result, mode)    if margin_lt is None: margin_lt = window + flank_width    if margin_rt is None: margin_rt = window + flank_width    if not direction < 0:        up = find_local_maxima(+indicator, num_steps=number_of_steps, threshold=threshold, margin_lt=margin_lt,                               margin_rt=margin_rt, thld_mode=thld_mode)        if direction > 0: return (up, indicator) if return_indicator else up    if not direction > 0:        dn = find_local_maxima(-indicator, num_steps=number_of_steps, threshold=threshold, margin_lt=margin_lt,                               margin_rt=margin_rt, thld_mode=thld_mode)        if direction < 0: return (dn, indicator) if return_indicator else dn    return (up, dn, indicator) if return_indicator else (up, dn)# see http://forums.tigsource.com/index.php?topic=14590.0def generate_noise(components, scaling=1.0):    N = (len(components) + 1) * 2    fy = np.empty(N, dtype=complex)    fy[0] = 0  # DC component    fy[N / 2] = 0  # center of spectrum    fy[1:N / 2] = np.array(components) * np.sqrt(N)  # absolute values = amplitudes, scaled by sqrt(N)    fy[1:N / 2] *= np.exp(1j * 2 * np.pi * np.random.rand(N / 2 - 1))  # angles = random phase shifts    fy[N / 2 + 1:] = np.flipud(np.conj(fy[1:N / 2]))  # second half = mirrored complex conjugate    y = np.fft.ifft(fy).real    if scaling is not None:        y -= np.mean(y)        y /= np.std(y)        y *= scaling    return y# see http://mathworld.wolfram.com/TransferFunction.html# "transfer function" usually refers to filtering an input signal in the frequency domain, which is equivalent to convolving it with the impulse response in the time domain. Here, the input signal is white noise (i.e. the input spectrum is constantly 1). The filtered output signal is colored noise.def generate_noise_from_tf(N, transfer_function, scaling=1.0):    return generate_noise(transfer_function(np.linspace(0, 1, N / 2)[1:]), scaling)def generate_white_noise(N, scaling=1.0):    return generate_noise_from_PSD(N, [1], scaling)def generate_pink_noise(N, scaling=1.0):     return generate_noise_from_tf(N, lambda f: 1 / np.sqrt(f), scaling)def generate_brownian_noise(N, scaling=1.0): return generate_noise_from_tf(N, lambda f: 1. / f, scaling)def generate_noise_from_PSD(N, PSD, scaling=1.0, plot_PSD=False):    if plot_PSD:        import pylab as pl        pl.figure()        pl.plot(np.linspace(1, N / 2, len(PSD)), 10 * np.log10(PSD), 'o')        pl.plot(np.arange(1, N / 2),                10 * np.log10(np.interp(np.arange(1, N / 2), np.linspace(1, N / 2, len(PSD)), PSD)), '-')    return generate_noise(np.interp(np.linspace(0, 1, N / 2), np.linspace(0, 1, len(PSD)), np.sqrt(PSD))[1:], scaling)def generate_noise_from_file(N, PSD_file, scaling=1.0):    return generate_noise_from_PSD(N, np.loadtxt(PSD_file), scaling)# see http://www.tmworld.com/article/322450-Windowing_Functions_Improve_FFT_Results_Part_I.php# see http://research.opt.indiana.edu/library/fourierbook/ch12.html# see http://en.wikipedia.org/wiki/Window_function# see http://www.katjaas.nl/FFTwindow/FFTwindow.htmldef psd(y, NFFT=256, windowing=True, plot=False,        transfer_function=None):  # power spectral density, independent of sample length, half amplitude compared to matplotlib.pyplot.psd()    numFreqs = NFFT / 2    if windowing: window = np.hanning(NFFT)    ind = np.arange(0, y.size - NFFT + 1, NFFT)    P = np.zeros((numFreqs, len(ind)))    for i in range(len(ind)):        thisy = y[ind[i]:ind[i] + NFFT]        if windowing: thisy = window * thisy        fy = np.fft.fft(thisy, n=NFFT)        P[:, i] = np.real(np.conjugate(fy[:numFreqs]) * fy[:numFreqs])    freqs = float(y.size) / NFFT * np.arange(numFreqs)    # if windowing: print float(NFFT) / (np.abs(window) ** 2).sum(), float(NFFT), (np.abs(window) ** 2).sum()    P = P.mean(axis=1) / NFFT    # P *= float(y.size) # amplify spectrum to compensate for variable sample length y.size    # P *= 2 # un-comment for compatibility to matplotlib.pyplot.psd()    if windowing: P *= float(NFFT) / (np.abs(        window) ** 2).sum()  # scale spectrum by the norm of the window to compensate for windowing loss; see Bendat & Piersol Sec 11.5.2    if plot:        if transfer_function is not None:            fit = np.empty(numFreqs)            fit[0] = 1            fit[1:] = transfer_function(freqs[1:]) ** 2            # fit *= 2 # un-comment for compatibility to matplotlib.pyplot.psd()        import matplotlib.pyplot as pl        pl.figure()        pl.plot(freqs, 10 * np.log10(P))        if transfer_function is not None: pl.plot(freqs, 10 * np.log10(fit))        # pl.xscale('log')        pl.xlim(0, max(freqs))        pl.grid(True)        pl.xlabel('frequency [a.u.]')        pl.ylabel('power spectral density [dB]')    return P, freqsdef detrend(y):    N = y.size    x = np.arange(0, N, dtype=float)    sum_x = sum(x)    sum_y = sum(y)    slope = (N * np.dot(x, y) - sum_x * sum_y) / (N * np.dot(x, x) - sum_x ** 2)    interception = (sum_y - slope * sum_x) / N    trend = x * slope + interception    y_detrended = y.copy() - trend    # y_detrended /= np.std(y_detrended)    return y_detrendeddef generate_test_signal(signal, N=4096, stddev=7.0):    t = [.1, .13, .15, .23, .25, .4, .44, .65, .76, .78, .81]    h = [4, -5, 3, -4, 5, -4.2, 2.1, 4.3, -3.1, 2.1, -4.2]    b = [4, 5, 3, 4, 5, 4.2, 2.1, 4.3, 3.1, 5.1, 4.2]    w = [.005, .005, .006, .01, .01, .03, .01, .01, .005, .008, .005]    x = np.linspace(0, 1, N)    if signal == 'blocks':        y = np.zeros(N)        for i in range(0, 11):            y[x >= t[i]] += h[i] / 2        y *= stddev / np.std(y)    elif signal == 'bumps':        y = 0        for i in range(0, 11):            y += b[i] * (1 + abs((x - t[i]) / w[i])) ** -4        y *= stddev / np.std(y)    elif signal == 'doppler':        y = np.sqrt(x * (1 - x)) * np.sin(2 * np.pi * 1.05 / (x + .05))        y *= stddev / np.std(y)    elif signal == 'heavisine':        y = 4 * np.sin(4 * np.pi * x) - np.sign(x - 0.3) - np.sign(0.72 - x)        y *= stddev / np.std(y)    else:        return None    return y